---
title: "p8105_hw6_ml4239"
author: "Man Luo"
date: "2018/11/7"
output: github_document
---
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ggplot2)
library(modelr)
library(leaps)
```

##P.1

###tidy the data.
```{r message=F}
homicide_data <- read_csv('./data/homicide-data.csv') 


homicide_tidy<-homicide_data %>% 
  mutate(city_state = str_c(city, ",", state),
         case_status = ifelse(disposition == "Closed without arrest" | disposition == "Open/No arrest", 0, 1)) %>%
  filter(victim_race != "Unknown") %>% 
   mutate(victim_race = ifelse(victim_race == "White", "White", "Nonwhite"),
          victim_race = factor(victim_race, levels = c("White", "Nonwhite")),
          victim_age = as.numeric(victim_age))%>% 
  filter(!(city_state %in% c('Dallas,TX', 'Phoenix,AZ','Kansas City,MO',"Tulsa,AL"))) %>% 
  na.omit(victim_age)
```
Create a city_state variable and a binary variable indicating the case status (if it is solved or not). factorized victim_race variable and making sure victim_age variables are all numeric.

###regression fpr the city of Baltimore, MD

```{r}

baltimore <-homicide_tidy %>% 
  filter(city_state == "Baltimore,MD")

fit_logistic = 
  baltimore %>% 
  glm(case_status ~ victim_age + victim_race + victim_sex, data = ., family = binomial())  #Save the output of glm as an R object

```

Obtain the estimate and confidence interval of the adjusted odds ratio for solving homicides comparing non-white victims to white victims keeping all other variables fixed.

```{r}

fit_logistic %>% 
  broom::tidy() %>% 
  mutate(OR = exp(estimate),
         conf.low = exp(estimate - std.error*1.96),
         conf.high = exp(estimate + std.error*1.96)) %>% 
  select(term, OR, conf.low, conf.high, p.value) %>% 
  knitr::kable()

```

Here we can see the estimate of the adjusted odds ratio for solving homicides comparing non-white is 0.4406080, and 95% confidence interval is (0.3129079, 0.6204234)

###dataframe with estimated ORs and CIs for each city.
```{r}
cities_summary <-homicide_tidy %>% 
  group_by(city_state) %>% 
  nest() %>% 
  mutate(models = map(data, ~glm(case_status ~ victim_age + victim_sex + victim_race, data = .x, family = binomial())),
         models = map(models, broom::tidy)) %>% 
  select(-data) %>% 
  unnest() %>% 
  filter(term == "victim_raceNonwhite") %>% 
  mutate(OR = exp(estimate),
         log_OR = estimate,
         conf.low = exp(estimate - std.error*1.96),
         conf.high = exp(estimate + std.error*1.96)) %>% 
  select(city_state, log_OR, OR, conf.low, conf.high, p.value)

cities_summary %>% 
  knitr::kable()
  
```

Get estimated ORs and CIs for each of the city in hte data set and create a table.

###plot that shows the estimated ORs and CIs for each city.
```{r}
cities_summary %>% 
  ggplot(aes(x = reorder(city_state, OR), y = OR)) +
  geom_point() +
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) +
  labs(title = "Estimated ORs and CIs for Each City",
       x = "city", 
       y = "ORs and CIs for nonwhite victims comparing to white victims",
       caption = "Data from the Washington Post") + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```

**Comments** The estimated ORS range from 0.1 to 1.2. `Boston, MA` has the least odd ratio and `Tampa, FL` has the most odds ratio for solving homicides comparing non-white victims to white victims keeping all other variables fixed. And we can also conclude from the plot that there tend to be more unsolved cases for nonwhite compared to white victims.(Birmingha, AL/ Tampa, FL are the only two exceptions)




##P.2

###Load and clean the data for regression analysis
```{r, message=FALSE}
birthweight<- read_csv("./data/birthweight.csv")
birth_tidy<-birthweight %>% 
  mutate(babysex = as.factor(recode(babysex, `1` = 0, `2` = 1)), # 0 represent male, 1 represents female
         frace = as.factor(frace), 
         mrace = as.factor(mrace),
         malform = as.factor(malform),
         bhead = as.numeric(bhead), 
         bwt = as.numeric(bwt * 0.00220462),
         mheight = as.numeric(mheight ))

table(is.na(birthweight))
```

Change babysex, frace, mrace, malform to factor variable and we can see there is no missing data.

###Build up regression model

Test the normal distribution assumption for the outcome
```{r}
birth_tidy %>% 
  ggplot(aes(x = bwt)) + 
  geom_bar()+
  labs(x = "birthweight",
       title = "Barplot of birthweight variable") 
```

We can tell that the birthweight outcome is like a Normal distribution so it follows the assumption.

```{r}
select_result <- regsubsets(bwt ~ ., data = birthweight)
md_sum<-summary(select_result)
md_sum
par(mar=c(4,4,1,1))
par(mfrow=c(1,2))
plot(2:10, md_sum$cp, xlab="No of parameters", ylab="Cp Statistic")
abline(0,1)
plot(2:10, md_sum$adjr2, xlab="No of parameters", ylab="Adj R2")
```

From the plot of CP statistics and Adjr2, we can tell there is no such different after 8 parameters, which are bhead, blength, delwt, fincome ,gaweeks, mrace, ppbmi, smoken.
  
Next we build the model and check its assumption.
  
  
```{r}
multi.fit8<-lm(bwt ~ bhead+ blength + delwt + fincome + gaweeks + mrace  + ppbmi + smoken, data = birth_tidy)
par(mfrow=c(2,2))
plot(multi.fit8) #check assumption
```
It fits the assumption quite nice. The residuals lies between 0 and QQ plot shows nice linear relationship which indicates it follows the normal distribution. 
###Factor driven regression model

For factor regression we choose the variable "babysex " and "mrace". 

Propose a regression model for birthweight. This model may be based on a hypothesized structure for the factors that underly birthweight, on a data-driven model-building process, or a combination of the two. 

###show a plot of model residuals against fitted values 

```{r}
birth_tidy %>% 
  add_predictions(multi.fit8) %>% 
  add_residuals(multi.fit8) %>% 
  ggplot(aes(x = pred, y = resid)) + 
  geom_point() + 
  geom_smooth(se = FALSE) + 
  labs(x = "Predicted value", 
       y = "Residual",
       title = "Predicted values vs. residuals plot for Final model")
```




###Compare your model to two others:

One using length at birth and gestational age as predictors (main effects only)
One using head circumference, length, sex, and all interactions (including the three-way interaction) between these

Make this comparison in terms of the cross-validated prediction error
```{r}
cv = 
  crossv_mc(birth_tidy, 100) %>%
  mutate(train = map(train, as_tibble),
         test = map(test, as_tibble)) 
  
cv = 
    cv %>% 
  mutate(model_own = map(train, ~lm(bwt ~  bhead + blength + delwt + fincome + gaweeks + mrace  + ppbmi + smoken, data = .x)),
         model_main = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
         model_inter = map(train, ~lm(bwt ~ babysex + blength + bhead + babysex * blength + babysex * bhead + blength * bhead + babysex * blength * bhead, data = .x))) %>% 
    mutate(rmse_m1 = map2_dbl(model_own, test, ~rmse(model = .x, data = .y)),
         rmse_m2 = map2_dbl(model_main, test, ~rmse(model = .x, data = .y)),
         rmse_m3 = map2_dbl(model_inter, test, ~rmse(model = .x, data = .y)))
  
  
cv %>% 
  select(starts_with("rmse")) %>% 
  gather(key = model, value = rmse) %>% 
  mutate(model = str_replace(model, "rmse_", ""),
         model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + geom_violin()
         
```
We can tell from the plot that m1 model (our model) has thee smallest rmse while the 'main effets only' model has the highest rmse. 




